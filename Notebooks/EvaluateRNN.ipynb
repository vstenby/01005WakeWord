{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Import torch stuff.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#pip install git+https://github.com/facebookresearch/WavAugment.git\n",
    "import augment\n",
    "\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "#Append the path outside so we can load bom1.\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import bom1.wakeword as wf\n",
    "import bom1.bom1 as bom1\n",
    "from   bom1.toolbox import WakewordDatasetRNN\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrasgaard\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/wakewordteam/RNN/runs/3ugstl75\" target=\"_blank\">trim-feather-8</a></strong> to <a href=\"https://wandb.ai/wakewordteam/RNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/wakewordteam/RNN/runs/3ugstl75?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fea64507630>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "lr = 3e-5\n",
    "nepoch = 200\n",
    "batch_size = 256\n",
    "\n",
    "config = {\n",
    "  \"learning_rate\": lr,\n",
    "  \"epochs\": nepoch,\n",
    "  \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "wandb.init(project=\"RNN\", entity=\"wakewordteam\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook is running on the cpu.\n"
     ]
    }
   ],
   "source": [
    "#Set the notebook to run on the GPU, if available.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'This notebook is running on the {device.type}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/work3/s164419/01005WakeWordData/RNN_data_10s_shift_5s_1_to_1/train/'\n",
    "train_dataset = WakewordDatasetRNN(f=lambda x: T.AmplitudeToDB()(T.Spectrogram(hop_length=40)(x)), folder=folder, normalize=True, #normalize the audio when reading it with torchaudio. \n",
    "                                              transforms = [#wf.AudioAugment(reverb = 100, snr = 15, pitch = 150, p = [0.5, 0.5, 0.5]),\n",
    "                                              wf.TransformMono(), \n",
    "                                              wf.Padder(22050*10)],\n",
    "                                              target_length = 1375\n",
    "                                              ) #sr * length of the clip\n",
    "\n",
    "folder = '/work3/s164419/01005WakeWordData/RNN_data_10s_shift_5s_1_to_1/val/'\n",
    "val_dataset = WakewordDatasetRNN(f=lambda x: T.AmplitudeToDB()(T.Spectrogram(hop_length=40)(x)), folder=folder, normalize=True, #normalize the audio when reading it with torchaudio. \n",
    "                                              transforms = [#wf.AudioAugment(reverb = 100, snr = 15, pitch = 150, p = [0.5, 0.5, 0.5]),\n",
    "                                              wf.TransformMono(), \n",
    "                                              wf.Padder(22050*10)],\n",
    "                                              target_length = 1375\n",
    "                                              ) #sr * length of the clip\n",
    "\n",
    "folder = '/work3/s164419/01005WakeWordData/RNN_data_10s_shift_5s_1_to_1/test/'\n",
    "test_dataset = WakewordDatasetRNN(f=lambda x: T.AmplitudeToDB()(T.Spectrogram(hop_length=40)(x)), folder=folder, normalize=True, #normalize the audio when reading it with torchaudio. \n",
    "                                              transforms = [#wf.AudioAugment(reverb = 100, snr = 15, pitch = 150, p = [0.5, 0.5, 0.5]),\n",
    "                                              wf.TransformMono(), \n",
    "                                              wf.Padder(22050*10)],\n",
    "                                              target_length = 1375\n",
    "                                              ) #sr * length of the clip\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bom1.models import RNN_V1\n",
    "\n",
    "rnn = RNN_V1().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight = torch.Tensor([20]).to(device))\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    rnn.load_state_dict(torch.load('../saved_models/RNN_V1/model.pth', map_location=device))\n",
    "\n",
    "x, targets, paths = next(iter(val_loader))\n",
    "outputs = rnn(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fea21802c50>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 7\n",
    "\n",
    "plt.plot(range(1375), (torch.sigmoid(outputs[idx]) > .75).detach())\n",
    "plt.plot(range(1375), targets[idx].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1375])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = (torch.sigmoid(outputs[idx]) > .75)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[109],\n",
       "        [110],\n",
       "        [111],\n",
       "        [112],\n",
       "        [113],\n",
       "        [114],\n",
       "        [676],\n",
       "        [677],\n",
       "        [678]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = targets[idx].nonzero().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'jaccard_similarity_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-767e497a7eeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjaccard_similarity_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mjaccard_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'jaccard_similarity_score'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_score(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(prediction, target):\n",
    "    prediction_threshold = (prediction > 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses   = []\n",
    "\n",
    "for epoch in tqdm(range(nepoch), total=nepoch, desc='Epoch'):\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss   = 0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        #Reset the gradients.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Fetch the data\n",
    "        x, targets, path = data\n",
    "\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "        #Forward pass\n",
    "        outputs = rnn(x).squeeze(-1)\n",
    "\n",
    "        #Calculate the loss\n",
    "        loss = criterion(outputs, targets) #BCE Loss.\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        contains_phrase = targets.any(dim=1)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            #Fetch the data\n",
    "            x, targets, path = data\n",
    "            x = x.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            #Forward pass\n",
    "            outputs = rnn(x).squeeze(-1)\n",
    "            \n",
    "            loss = criterion(outputs, targets) #BCE Loss.\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    #Find the average batch loss.\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    val_loss   = val_loss / len(val_loader)\n",
    "    \n",
    "    #Append the training loss and the validation loss.\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    wandb.log({'val_loss': val_loss,'train_loss': train_loss})\n",
    "\n",
    "    torch.save(rnn.state_dict(), os.path.join('./saved_models/RNN_V1', 'model2.pth'))\n",
    "    \n",
    "    print(f'[{epoch}] Train loss: {train_loss}, Val loss: {val_loss}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50fd61b4ba0bc6d9fddaa9c6d1b42a79e1f6c82c11b4840c107fc501d8d17b12"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
